{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "725ef198-6a0b-489c-bf17-de791ff3ba0a",
   "metadata": {},
   "source": [
    "# Deploy Versioned Airflow DAG Script Artifact\n",
    "\n",
    "A lot of serverless AWS Service supports versioning and alias for deployment. It made the blue / green deployment, canary deployment, and rolling back super easy.\n",
    "\n",
    "- [AWS Lambda Versioning and Alias](https://docs.aws.amazon.com/lambda/latest/dg/configuration-versions.html)\n",
    "- [AWS StepFunction Versioning and Alias](https://docs.aws.amazon.com/step-functions/latest/dg/auth-version-alias.html)\n",
    "- [AWS SageMaker Model Registry Versioning](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html)\n",
    "\n",
    "However, Airflow DAG does not support this feature yet. This library provides a way to manage Airflow DAG versioning and alias so you can deploy Airflow DAG with confidence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598bd2b7-9f37-4f0f-a678-d0a2d59b248a",
   "metadata": {},
   "source": [
    "## Quick Start\n",
    "\n",
    "First, import the ``AirflowDagArtifact`` from ``airflow_dag_artifact.api``. The ``AirflowDagArtifact`` is an abstraction of an Airflow DAG script. Also, we need to import the ``BotoSesManager`` object to give our artifact manager AWS permission. In this example, you need AWS S3 and AWS DynamoDB permission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123f7dbe-8601-47e0-a3c1-6b493a5b0226",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from airflow_dag_artifact.api import AirflowDagArtifact\n",
    "from boto_session_manager import BotoSesManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797cab5d-aa1a-4483-a2b7-ab8f4d1db2e6",
   "metadata": {},
   "source": [
    "We need to import additional library to improve our development experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "250e42cc-6f2f-4b49-9154-9130af0a28e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Path to the artifact files\n",
    "from pathlib import Path\n",
    "# pretty printer for debugging\n",
    "from rich import print as rprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c542652f-bbce-4eb1-8129-3b39aa4650e2",
   "metadata": {},
   "source": [
    "First, let's use a local AWS CLI profile to create the boto session manager object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a445ce-859d-4b32-a7c5-7f213a9ff736",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm = BotoSesManager(profile_name=\"bmt_app_dev_us_east_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a6806-171a-4f13-a9e8-9b4daf4a7b56",
   "metadata": {},
   "source": [
    "### Create Airflow DAG Script Artifact\n",
    "\n",
    "This code block will create the Airflow DAG script artifact. Firstly, let's create the path to the script and display the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50558a1b-5f2b-45c7-a652-e70c7d4aa7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import datetime\n",
      "\n",
      "from airflow import DAG\n",
      "from airflow.operators.empty import EmptyOperator\n",
      "\n",
      "with DAG(\n",
      "    dag_id=\"my_dag_name\",\n",
      "    start_date=datetime.datetime(2021, 1, 1),\n",
      "    schedule=\"@daily\",\n",
      "):\n",
      "    EmptyOperator(task_id=\"task\")\n"
     ]
    }
   ],
   "source": [
    "dir_here = Path.cwd().absolute()\n",
    "dir_project_root = dir_here.parent\n",
    "path_airflow_dag_script_1_py = dir_here.joinpath(\"airflow_dag_script_1.py\")\n",
    "print(path_airflow_dag_script_1_py.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a4b15c-3922-40c3-af00-d2b144217aa7",
   "metadata": {},
   "source": [
    "Then we create an Airflow DAG script artifact object. We need to specify ``aws_region``, ``s3_bucket``, ``s3_prefix`` and ``dynamodb_table_name`` to define the artifact store backend. It uses the [versioned](https://github.com/MacHu-GWU/versioned-project) Python library under the hood to manage the artifact content and its metadata. Also, you have to give it a unique ``artifact_name``, it will become part of the naming convention of artifact S3 location. And we pass the ``path_airflow_dag_script`` to define where is the Airflow DAG script located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "683a3146-76cf-4d10-ab35-75b8fba17de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airflow_dag_artifact-project/examples/airflow_dag_script_1.py\n"
     ]
    }
   ],
   "source": [
    "aws_region = bsm.aws_region\n",
    "s3_bucket = f\"{bsm.aws_account_id}-{bsm.aws_region}-artifacts\"\n",
    "s3_prefix = \"versioned-artifacts\"\n",
    "dynamodb_table_name = \"versioned-artifacts\"\n",
    "\n",
    "airflow_dag_script_artifact = AirflowDagArtifact(\n",
    "    aws_region=aws_region,\n",
    "    s3_bucket=s3_bucket,\n",
    "    s3_prefix=s3_prefix,\n",
    "    dynamodb_table_name=dynamodb_table_name,\n",
    "    artifact_name=\"airflow_dag_script_1\",\n",
    "    path_airflow_dag_script=path_airflow_dag_script_1_py,\n",
    ")\n",
    "print(airflow_dag_script_artifact.path_airflow_dag_script.relative_to(dir_project_root.parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c267b7-d880-4f86-a851-8ecbd8281097",
   "metadata": {},
   "source": [
    "``airflow_dag_artifact`` uses AWS S3 to store the artifact files and AWS DynamoDB to store the artifact metadata. Yet, the S3 bucket and DynamoDB table are not created yet, so we have to call the ``.bootstrap`` method to create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f583bd85-9502-4cb1-80e8-36669b97b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "airflow_dag_script_artifact.repo.purge_all()\n",
    "airflow_dag_script_artifact.bootstrap(bsm=bsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae434c-f3c4-4ad8-8b32-2fbf9fec4499",
   "metadata": {},
   "source": [
    "Now we can just call the ``put_artifact`` method to deploy the artifact as the ``LATEST``. It will return an ``Artifact`` object includes the metadata of the artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95fd51bb-e400-4f7b-b84f-b0657072b37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Artifact</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'airflow_dag_script_1'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LATEST'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">update_at</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">533403</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tzinfo</span>=<span style=\"color: #800080; text-decoration-color: #800080\">datetime</span>.timezone.utc<span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">s3uri</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'s3://111122223333-us-east-1-artifacts/versioned-artifacts/airflow_dag_script_1/LATEST.py'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">sha256</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'18b287e24cfa4d2bac3a03734c5dcee9ed19dbda05c5ae97da4a3f9e895145b3'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mArtifact\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mname\u001b[0m=\u001b[32m'airflow_dag_script_1'\u001b[0m,\n",
       "    \u001b[33mversion\u001b[0m=\u001b[32m'LATEST'\u001b[0m,\n",
       "    \u001b[33mupdate_at\u001b[0m=\u001b[1;35mdatetime\u001b[0m\u001b[1;35m.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2023\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m20\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m31\u001b[0m, \u001b[1;36m533403\u001b[0m, \u001b[33mtzinfo\u001b[0m=\u001b[35mdatetime\u001b[0m.timezone.utc\u001b[1m)\u001b[0m,\n",
       "    \u001b[33ms3uri\u001b[0m=\u001b[32m's3://111122223333-us-east-1-artifacts/versioned-artifacts/airflow_dag_script_1/LATEST.py'\u001b[0m,\n",
       "    \u001b[33msha256\u001b[0m=\u001b[32m'18b287e24cfa4d2bac3a03734c5dcee9ed19dbda05c5ae97da4a3f9e895145b3'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "artifact = airflow_dag_script_artifact.put_artifact(metadata={\"foo\": \"bar\"})\n",
    "rprint(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6ce7b1-79ad-47cc-bade-0c862e3e0108",
   "metadata": {},
   "source": [
    "If you want to deploy your Airflow dag via CLI, terraform, or any other tool, you can retrieve the versioned dag artifact from S3. You can use the ``get_artifact_s3path()`` method to get the latest artifact S3 uri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e15d7f5-d5d3-460f-bb52-a22eec14ca31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://111122223333-us-east-1-artifacts/versioned-artifacts/airflow_dag_script_1/LATEST.py\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://console.aws.amazon.com/s3/object/111122223333-us-east-1-artifacts?prefix=versioned-artifacts/airflow_dag_sc</span>\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">ript_1/LATEST.py</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[4;94mhttps://console.aws.amazon.com/s3/object/111122223333-us-east-1-artifacts?\u001b[0m\u001b[4;94mprefix\u001b[0m\u001b[4;94m=\u001b[0m\u001b[4;94mversioned\u001b[0m\u001b[4;94m-artifacts/airflow_dag_sc\u001b[0m\n",
       "\u001b[4;94mript_1/LATEST.py\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s3path = airflow_dag_script_artifact.get_artifact_s3path()\n",
    "print(s3path.uri)\n",
    "rprint(s3path.console_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2190bb3-91bc-47fe-ba7b-593c7219de57",
   "metadata": {},
   "source": [
    "Once you made a release to production, you should create an immutable version of your artifact so you can roll back anytime. You can use ``publish_artifact_version()`` method to publish a new version from the Latest. The version is simply a immutable snapshot of your latest artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47a79302-85d7-4e0d-856d-684286cba4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Artifact</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'airflow_dag_script_1'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">update_at</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">244969</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tzinfo</span>=<span style=\"color: #800080; text-decoration-color: #800080\">datetime</span>.timezone.utc<span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">s3uri</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'s3://111122223333-us-east-1-artifacts/versioned-artifacts/airflow_dag_script_1/000001.py'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">sha256</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'18b287e24cfa4d2bac3a03734c5dcee9ed19dbda05c5ae97da4a3f9e895145b3'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mArtifact\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mname\u001b[0m=\u001b[32m'airflow_dag_script_1'\u001b[0m,\n",
       "    \u001b[33mversion\u001b[0m=\u001b[32m'1'\u001b[0m,\n",
       "    \u001b[33mupdate_at\u001b[0m=\u001b[1;35mdatetime\u001b[0m\u001b[1;35m.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2023\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m20\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m34\u001b[0m, \u001b[1;36m244969\u001b[0m, \u001b[33mtzinfo\u001b[0m=\u001b[35mdatetime\u001b[0m.timezone.utc\u001b[1m)\u001b[0m,\n",
       "    \u001b[33ms3uri\u001b[0m=\u001b[32m's3://111122223333-us-east-1-artifacts/versioned-artifacts/airflow_dag_script_1/000001.py'\u001b[0m,\n",
       "    \u001b[33msha256\u001b[0m=\u001b[32m'18b287e24cfa4d2bac3a03734c5dcee9ed19dbda05c5ae97da4a3f9e895145b3'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "artifact = airflow_dag_script_artifact.publish_artifact_version()\n",
    "rprint(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee0d6c-3253-4267-b0b0-cc47b3c1d34a",
   "metadata": {},
   "source": [
    "When you are doing roll back, you need to pass the S3 uri of the historical version of artifact. You can use the ``get_artifact_s3path(version=...)`` method to get the S3 uri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60ebcb70-320b-4f32-9276-1d3068b74cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://111122223333-us-east-1-artifacts/versioned-artifacts/airflow_dag_script_1/000001.py\n"
     ]
    }
   ],
   "source": [
    "s3path = airflow_dag_script_artifact.get_artifact_s3path(version=1)\n",
    "print(s3path.uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7342f462-7e4d-4e63-9d49-108ef77d6a2a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Now you get the idea of how to manage Airflow DAG artifacts using ``airflow_dag_artifact`` Python library. With versioned artifacts, you can easily enable the blue/green, canary deployment, and have the confidence to roll back when there's a failure in production. I highly suggest this pattern in production project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d9e614-0c4f-46e2-8ee6-5337a1b294c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
